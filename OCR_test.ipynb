{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f79bf11-fad6-469a-8410-f17dee2133d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5409a9e6-4505-4bd9-b8d7-7965227103c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF pages to images\n",
    "def pdf_to_images(pdf_path):\n",
    "    print(\"Converting PDF to images...\")\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap(dpi=300)\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        images.append(np.array(img))\n",
    "        print(f\"Extracted image from page {page_num + 1}\")\n",
    "    print(\"PDF conversion complete.\\n\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c185b67a-bd64-4a94-b405-caad21af0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class mapping\n",
    "your_classes = {0: 'column_icon', 1: 'column_icon', 2: 'column_number', 3: 'column_length', 4: 'column_width'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "106ea24f-eabd-4fbe-9d68-1a18f3503c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to configure and load the Detectron2 model\n",
    "def configure_detectron2():\n",
    "    print(\"Configuring Detectron2 model...\")\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # Ensure this matches your model's trained classes\n",
    "    cfg.MODEL.WEIGHTS = \"C:\\OCR\\Output\\model_final.pth\"  # Path to your model file\n",
    "    cfg.MODEL.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"Detectron2 configuration complete.\\n\")\n",
    "    return cfg, DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "642dd4bc-ea40-47e8-a1c1-4b69c3828827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process images using Detectron2 model\n",
    "def detect_objects(images, predictor, cfg):\n",
    "    print(\"Detecting objects in images...\")\n",
    "    results = []\n",
    "    for i, image in enumerate(images):\n",
    "        outputs = predictor(image)\n",
    "        print(f\"Objects detected in image {i + 1}: {len(outputs['instances'])} instances found.\")\n",
    "        v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        \n",
    "        # Display the detected objects\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(out.get_image()[:, :, ::-1])\n",
    "        plt.title(f\"Detected objects in image {i + 1}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        results.append((out.get_image()[:, :, ::-1], outputs[\"instances\"]))\n",
    "    print(\"Object detection complete.\\n\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5abec-964e-4542-9bc5-3d55722b15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Extracted image from page 1\n",
      "PDF conversion complete.\n",
      "\n",
      "Configuring Detectron2 model...\n",
      "Detectron2 configuration complete.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malar\\anaconda3\\envs\\OCR\\lib\\site-packages\\fvcore\\common\\checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (5, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (5,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (16, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (16,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting objects in images...\n"
     ]
    }
   ],
   "source": [
    "# Function to extract dimensions from detected objects\n",
    "def extract_dimensions(instances, image):\n",
    "    print(\"Extracting dimensions from detected objects...\")\n",
    "    columns_data = []\n",
    "    for i in range(len(instances)):\n",
    "        instance = instances[i]\n",
    "        box = instance.pred_boxes.tensor.numpy()[0]\n",
    "        column_width = box[2] - box[0]\n",
    "        column_height = box[3] - box[1]\n",
    "        columns_data.append({\n",
    "            \"Column Number\": i + 1,\n",
    "            \"Column Length (meters)\": column_height / 100,\n",
    "            \"Column Width (meters)\": column_width / 100\n",
    "        })\n",
    "    print(f\"Extracted dimensions for {len(columns_data)} columns.\\n\")\n",
    "    return columns_data\n",
    "\n",
    "# Function to export data to Excel\n",
    "def export_to_excel(data, output_path):\n",
    "    print(\"Exporting data to Excel...\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"Data successfully exported to {output_path}\\n\")\n",
    "\n",
    "# Main function to execute the pipeline\n",
    "def main(pdf_path, output_excel_path):\n",
    "    images = pdf_to_images(pdf_path)\n",
    "    cfg, predictor = configure_detectron2()\n",
    "    detected_results = detect_objects(images, predictor, cfg)\n",
    "    \n",
    "    all_columns_data = []\n",
    "    for img_idx, (visualized_image, instances) in enumerate(detected_results):\n",
    "        print(f\"Processing detected objects in image {img_idx + 1}...\")\n",
    "        columns_data = extract_dimensions(instances, images[img_idx])\n",
    "        all_columns_data.extend(columns_data)\n",
    "    \n",
    "    export_to_excel(all_columns_data, output_excel_path)\n",
    "    print(\"Process complete.\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\OCR\\Centerline_test.pdf\"  # Specify the path to the PDF file\n",
    "    output_excel_path = \"column_data.xlsx\"\n",
    "    main(pdf_path, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854c15e-0a1b-486b-a5f9-3e27b64ee1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCR",
   "language": "python",
   "name": "ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
